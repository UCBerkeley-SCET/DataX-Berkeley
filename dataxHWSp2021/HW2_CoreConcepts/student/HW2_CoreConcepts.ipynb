{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh9vm0LmCj8o"
   },
   "source": [
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A1dHrL8Co9m"
   },
   "source": [
    "___\n",
    "\n",
    "#### NAME:\n",
    "\n",
    "#### STUDENT ID:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLCbCo9ACxD9"
   },
   "source": [
    "#  HW2: Core Concepts\n",
    "Total 70 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOtYdq62F2BY"
   },
   "source": [
    "## 1. Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHW2HYCwC2si"
   },
   "source": [
    "Run the following cell to load the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aYsDP-ayC6O6"
   },
   "outputs": [],
   "source": [
    "## Load the required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbgkgW9MVGDq"
   },
   "source": [
    "### 1.a Introduction to Regularization (6 points)\n",
    "\n",
    "In linear regression, our goal is to fit a linear model to the data and we find that linear model by solving the following optimization problem:\n",
    "\n",
    "$$ \\text{argmin}_{w \\in \\mathbb{R^d}} ||Xw-y||_2^2,$$\n",
    "\n",
    "where $X$ is a $n \\times d$ matrix containing $n$ data points each of which has $d$ features, and $y$ is a one-dimensional vector of size $n$ containing the corresponding responses. \n",
    "\n",
    "The optimum solution $w^*$ staisfies the following equation (why?): \n",
    "$$ (X^TX)w^* = X^Ty.$$\n",
    "\n",
    "If $X$ is full rank, then we can solve for a unique solution $w^* = (X^TX)^{-1}X^Ty$. This formula was the one you used in the previous homework. Note that this derivation fails when $X^TX$ is not invertible. Even in that case, the features of the data could be close to collinear causing the input matrix $X$ to have singular values very close to 0, which in turn leads to numerical instability in computing the inverse of $X^TX$. \n",
    "\n",
    "A very simple solution to these issues is to consider $w_{ridge}^* = (X^TX+\\lambda I)^{-1}X^Ty$ as the solution for some $\\lambda > 0$. Note that $X^TX+\\lambda I$ is always invertible and it's eigenvalues are at least $\\lambda$ (why?). One can show that this is the solution to the following problem which is indeed the **ridge regression**: \n",
    "\n",
    "$$ \\text{argmin}_{w \\in \\mathbb{R^d}} ||Xw-y||_2^2 + \\lambda||w||_2^2.$$ \n",
    "\n",
    "The difference between this problem and linear regression is that we are penalizing the entries of $w$ from becoming too large. This is also a form of regularization that could be used to prevent overfitting to the data. Make sure you understand the concept of overfitting and regularization by going through these [slides](https://datax.berkeley.edu/wp-content/uploads/2020/09/slides-m220-theory-tools-regularization.pdf). \n",
    "\n",
    "As you can see, in ridge regression, all parameters are regularized equally, which is a special case of [Tikhonov regularization](https://en.wikipedia.org/wiki/Tikhonov_regularization). Note that $\\lambda$ is a **hyperparamter** that measures the sensitivity to the values in $w$. You will see how to choose $\\lambda$ in the next part where we talk about validation sets and cross-validation. \n",
    "\n",
    "Now, we use ridge regression to train a model on the dataset you used in the previous homework. Run the following cell to load the cleaned dataset with dummy variables and split it into training and test sets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9b1OSDkOV2NM"
   },
   "outputs": [],
   "source": [
    "## Run this cell, no need to modify\n",
    "df_games = pd.read_csv(\"HW1_dataset_cleaned_with_dummies.csv\") \n",
    "\n",
    "x = df_games[['Critic_Score','Critic_Count', 'User_Score', 'User_Count', \n",
    "                       'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', \n",
    "                       'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy', \n",
    "                       'DC', 'DS', 'GBA', 'GC', 'PC', 'PS', 'PS2', 'PS3', 'PS4', 'PSP', 'PSV', \n",
    "                       'Wii', 'WiiU', 'X360', 'XB', 'XOne', 'E', 'E10+', 'K-A', 'M', 'RP','T']].values\n",
    "y = df_games['Global_Sales'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "N1nsmC-FU78b"
   },
   "source": [
    "**1.a.1)** Use scikit-learn function [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) to build your ridge regression model on the training data. Store your model in `ridge_model`. \n",
    "\n",
    "> **Setting:** `alpha=100` and `fit_intercept=True`.\n",
    "\n",
    "Note that bias term is not regularized in ridge rigression. Read more about it [here](https://stackoverflow.com/questions/12578336/why-is-the-bias-term-not-regularized-in-ridge-regression). \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a1\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x8iA0eNIa1Dg"
   },
   "outputs": [],
   "source": [
    "## your code here\n",
    "ridge_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pbJ41AScZ2vw"
   },
   "source": [
    "**1.a.2)** Calculate the **mean-squared-error** for the training data using scikit-learn function [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean_squared_error#sklearn.metrics.mean_squared_error) and store it in `ridge_train_error`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a2\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1Npa5QqcUmK",
    "outputId": "f30896bb-f637-4cc2-b84d-533695404a91"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "ridge_train_error = ...\n",
    "print(ridge_train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ea1qoFDtax2M"
   },
   "source": [
    "The training error you obtained in question 4.3 of HW1 was 3.311. Compare this error with the one you obtained above. Did you expect the ridge regression error to be higher or lower? Why? (You don't need to write any answers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "H88VQ7Psbjnl"
   },
   "source": [
    "**1.a.3)** Now, compute the **mean-squared-error** for the test set and store it in `ridge_test_error`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a3\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ri4fQXPfeHwP",
    "outputId": "977d156b-d6a6-47cb-d82d-e03b0d528f22"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "ridge_test_error = ...\n",
    "print(ridge_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCDSlaROcAgg"
   },
   "source": [
    "The test error you obtained in question 4.4 of HW1 was 1.419. Compare this error with the one you obtained above. As we mentioned before, regularization is a solution to generalization issues by preventing the model to overfit the data. Is your observation aligned with this statement? Has regularization helped you to do better on the test set? (You don't need to write any answers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSrARqd-ejt9"
   },
   "source": [
    "## 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roFt2j1NiYM1"
   },
   "source": [
    "### 2.a Validation Set (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEDuz-YOc6L8"
   },
   "source": [
    "A hyperparameter is a parameter whose value is used to control the learning process. Whereas the model parameters specify how to transform the input data into the desired output, the hyperparameters define how our model is actually structured. In ridge regression for example, $\\lambda$ is a hyper-parameter that needs to be set before training the model. \n",
    "\n",
    "We can choose our model's hyperparamters by evaluating the model's ability to generalize to unseen data. You must not touch the test dataset more than once. If you use the test set for this evaluation, you will end up fitting the model architecture to the test set, losing the ability to truely evaluate how the model performs on unseen data. This is sometimes referred to as [data leakage](https://machinelearningmastery.com/data-leakage-machine-learning/).\n",
    "\n",
    "A solution to this issue is to split the total dataset into three subsets: training set, validation set, and test set. For a particular choice of hyperparameters, we train our model on the training set, and then evaluate it on the validation set. Then, we compare different choices of hyperparameters based on how their corresponding model performs on the validation set and finally pick up the one that gives us the best performance on the validation set. \n",
    "\n",
    "Let's use this approach to set $\\lambda$ in ridge regression. The training and test sets we used above are given to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zbwWMPHMhmst"
   },
   "outputs": [],
   "source": [
    "## Run this cell, no need to modify\n",
    "x = df_games[['Critic_Score','Critic_Count', 'User_Score', 'User_Count', \n",
    "                       'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', \n",
    "                       'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy', \n",
    "                       'DC', 'DS', 'GBA', 'GC', 'PC', 'PS', 'PS2', 'PS3', 'PS4', 'PSP', 'PSV', \n",
    "                       'Wii', 'WiiU', 'X360', 'XB', 'XOne', 'E', 'E10+', 'K-A', 'M', 'RP','T']].values\n",
    "y = df_games['Global_Sales'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b_8C5Cl5iRLa"
   },
   "source": [
    "**2.a.1)** Use scikit-learn function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) again to split the training set into a smaller training set and a validation set. Store the result in `x_train_prime`, `x_val`, `y_train_prime`, and `y_val`.\n",
    "\n",
    ">**Setting:** Use 10% of the training dataset for the validation set and let `random_state=1399`.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a1\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "r9Mn60EjiDWP"
   },
   "outputs": [],
   "source": [
    "## your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iKmmRLKpkP2x"
   },
   "source": [
    "**2.a.2)** Sweep hyperparameters in the array `alphas` given to you below and pick the one with which the ridge regression model trained on the training set performs the best on the validation set. Store the result in `alpha_best`. Use **mean-squared-error** to measure the performance of your model on the validation set. \n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Y1Ok2Filv1D",
    "outputId": "5db14266-6da8-4038-97db-f528b9e7433b"
   },
   "outputs": [],
   "source": [
    "## your code here\n",
    "alphas = 10 ** np.linspace(-3, 4, num=50, endpoint=True)\n",
    "\n",
    "alpha_best = ...\n",
    "print(alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0ARV6wlWvvgT"
   },
   "source": [
    "**2.a.3)** Train a ridge regression model with hyperparameter `alpha_best` on the larger training dataset, i.e. `x_train` and `y_train`. Then, compute the **mean-squared-error** for the test set and store it in `tuned_ridge_test_error`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a3\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKBUK6rOwZ3D",
    "outputId": "c452ae47-9115-4c39-fc68-e358c994f452"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "tuned_ridge_test_error = ...\n",
    "print(tuned_ridge_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tie1svhUxDHu"
   },
   "source": [
    "Compare the error you obtained above with the one you got in question 1.3. Think about whether choosing the \"best\" hyper-parameter using a validation set helps the model to generalize better. (You don't need to write any answers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDOnMYfsexIn"
   },
   "source": [
    "### 2.b Cross-Validation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZVNid9iFfPM"
   },
   "source": [
    "Run the following cell to load the required module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sUvIeaOZFbVf"
   },
   "outputs": [],
   "source": [
    "## Load the required module\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4mCjRJd1LYS"
   },
   "source": [
    "Setting aside a validation set works well, but comes at a cost, since we cannot use the validation\n",
    "data for training. Since having more data generally improves the quality of the trained model,\n",
    "we may prefer not to let that data go to waste, especially if we have little data to begin with\n",
    "and/or collecting more data is expensive. **Cross-validation** is an alternative to having a dedicated validation set.\n",
    "\n",
    "$k$-fold cross-validation works as follows:\n",
    "\n",
    "1.   Shuffle the data and partition it into $k$ equally-sized (or as equal as possible) blocks.\n",
    "2.   For $i= 1, ..., k$,\n",
    " * Train the model on all the data except block $i$.\n",
    " * Evaluate the model (i.e. compute the validation error) using block i.\n",
    "3.   Average the $k$ validation errors; this is our final estimate of the true error.\n",
    "\n",
    "As before, the training and test data are given to you below. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PK-lpg3je21w"
   },
   "outputs": [],
   "source": [
    "## Run this cell, no need to modify\n",
    "x = df_games[['Critic_Score','Critic_Count', 'User_Score', 'User_Count', \n",
    "                       'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', \n",
    "                       'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy', \n",
    "                       'DC', 'DS', 'GBA', 'GC', 'PC', 'PS', 'PS2', 'PS3', 'PS4', 'PSP', 'PSV', \n",
    "                       'Wii', 'WiiU', 'X360', 'XB', 'XOne', 'E', 'E10+', 'K-A', 'M', 'RP','T']].values\n",
    "y = df_games['Global_Sales'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lALK-QSX3ayb"
   },
   "source": [
    "**2.b.1)** Sweep through the array `alphas` given to you below and pick the best hyperparameter by applying **4-fold** cross validation on the training set and store the hyperparameter you choose in `alpha_best_cv`. Use scikit-learn function [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). \n",
    "\n",
    ">**Setting:** Whenever you call `cross_val_score`, set `cv=kf` where `kf` is given to you bellow. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HLqOPsTkneu",
    "outputId": "1607df6c-23cc-49f5-bd51-09313f15e455"
   },
   "outputs": [],
   "source": [
    "## your code here\n",
    "alphas = 10 ** np.linspace(-3, 4, num=50, endpoint=True)\n",
    "kf = KFold(4, shuffle=True, random_state=0)\n",
    "\n",
    "alpha_best_cv = ...\n",
    "print(alpha_best_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DL8FKMnTRpRw"
   },
   "source": [
    "**2.b.2)** Train a ridge regression model with hyperparameter `alpha_best_cv` on the training dataset, i.e. `x_train` and `y_train`. Then, compute the **mean-squared-error** for the test set and store it in `cv_ridge_test_error`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b2\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jT3KqVdwRTN7",
    "outputId": "b3202d90-9b07-46b7-f095-53945cc934f4"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "cv_ridge_test_error = ...\n",
    "print(cv_ridge_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIe_FAzG-RZe"
   },
   "source": [
    "Compare this error with the ones you got in questions 1.3 and 2.a.3. Recall that the test error of your linear regression (in HW1) was 1.419. (You don't need to write any answers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I12mmHj6JWOk"
   },
   "source": [
    "# Classification with Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa-ovTQTFOnd"
   },
   "source": [
    "Run the following cell to load the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Na_S0hdE67v5"
   },
   "outputs": [],
   "source": [
    "## Load the required modules\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, validation_curve, cross_val_score, GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdZffx2ZPSsW"
   },
   "source": [
    "We will now work on a medical dataset from https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. Our objective is to diagnose whether a tumor is benign or malicious, represented as `'B'` and `'M'` respectively in the `'diagnosis'` field of the dataset. Available features are compueted from images of fine needle aspirate (FNA) of tumors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "0L8VnVBNKV_g",
    "outputId": "cb2e7b69-0e92-4f99-b6d3-8fcd3d9baee1"
   },
   "outputs": [],
   "source": [
    "df_med = pd.read_csv(\"HW2_medical_data.csv\")\n",
    "df_med.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSbh42SPHaMq"
   },
   "source": [
    "We hold out 20% of the data for assessment of model generalizability (i.e. for model testing). The rest 80% can be used for the training stage including hyperparameter tunings. We will use 5-fold cross-validation with partitions among the samples specified by the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) instance `kf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "IMIwY1CYPKl4"
   },
   "outputs": [],
   "source": [
    "## Run this cell without modifications\n",
    "df_train, df_test = train_test_split(df_med,test_size=0.2,random_state=0)\n",
    "kf = StratifiedKFold(5,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHXNFQU-JaAD"
   },
   "source": [
    "We select the `'diagnosis'` field as the outcome variable and simply drop the outcome and the patient id from the original dataset to form the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TN-Fw-xwQJFk"
   },
   "outputs": [],
   "source": [
    "## Run this cell without modifications\n",
    "X_train = df_train.drop(['id','diagnosis'],axis=1)\n",
    "y_train = df_train.diagnosis\n",
    "X_test = df_test.drop(['id','diagnosis'],axis=1)\n",
    "y_test = df_test.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO2GtA5_LbGj"
   },
   "source": [
    "`plot_cv_curve` is a helper function that will be handy for plotting the cross-validation curves later. For now simply execute this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6sVv3GChXO9c"
   },
   "outputs": [],
   "source": [
    "## Run this cell without modifications\n",
    "def plot_cv_curve(hyperparm_grid,train_scores,val_scores):\n",
    "  ax = plt.subplot(111)\n",
    "  ax.errorbar(hyperparm_grid,np.mean(train_scores,axis=1),yerr=np.std(train_scores,axis=1),label=\"train\")\n",
    "  ax.errorbar(hyperparm_grid,np.mean(val_scores,axis=1),yerr=np.std(val_scores,axis=1),label=\"validation\")\n",
    "  ax.set_xlabel('Hyperparameter')\n",
    "  ax.set_ylabel('Score')\n",
    "  ax.legend()\n",
    "  ax.grid()\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeGzpJVcoV5P"
   },
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oT2XEAJL3L-"
   },
   "source": [
    "We can build classifier with great interprebility through [logistic regression](https://datax.berkeley.edu/wp-content/uploads/2020/09/slides-m140-logistic-reg-sklearn.pdf?fbclid=IwAR2Ah4T7wfG2Jm-Ml8mB_mDM1zc6In5DLK1FtQqM8fp3AoaQMfWofTiDVnw). To get started, we train a logit model with default hyperparameters and perform 5-fold cross-validatoin with the help of `kf`. Each fold gives one score, and we average them to get the overall validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGAWba90H9Nt",
    "outputId": "ca4f2f54-28d2-46de-fafe-d66f0c992af4"
   },
   "outputs": [],
   "source": [
    "## Demo: training a default logit model and cross-validate\n",
    "logit = LogisticRegression(max_iter=5000)\n",
    "cv_scores = cross_val_score(logit,X_train,y_train,cv=kf)\n",
    "print (\"Cross-Validation Accuracies:\", cv_scores)\n",
    "print (\"Overall CV score is:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QxgIPTi2RQJ3"
   },
   "source": [
    "The validation accuracy is already quite good! Can we further improve it by using different hyperparamers? \n",
    "***\n",
    "### 3.a Cross-Validation Curve: Regularization (3 points)\n",
    "\n",
    "**3.a)** The major hyperparameter for the linear logit model is the regularization parameter `'C'`. See the [sklearn API](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) for usage. Ten potential choices for `'C'` are given in the `C_grid` array below. Train logit models for each C in `C_grid`, and record the training and validation scores from the 5-fold cross-validation with the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) `kf`.\n",
    "\n",
    "There is one training score and one validation score for each fold of the cross-validation and each hyperparameter choice.\n",
    "- The training score is the model's accuracy on their train dataset in the cross-validation fold. \n",
    "- The validation score is the model's accuracy on their validation dataset in the cross-validation fold.\n",
    "\n",
    "Therefore, you will get 10 (hyperparameter choices) $\\times$ 5 (folds)=50 total training scores and 50 validation scores. \n",
    "\n",
    "**Store your answers in the following format:**\n",
    "1. The obtained training scores are stored in an array with shape (10,5) called `train_scores`.\n",
    "2. The validation scores are stored an array with shaped (10,5) called `val_scores`.\n",
    "\n",
    "**Important points to follow (in order to pass the tests):**\n",
    "- The first axis should align with the elements in `C_grid`, and the second axis corresponds to the 5 folds in the cross-validation as specified by `kf`.\n",
    "- If you have the format correct, the `plot_cv_curve` function should be able to produce reasonble error plots with bars indicating the standard deviation of score for a given hyperparameters choice.\n",
    "- **Make sure all the training converges**, which may be not the case under the default solver setting. The solver can be configured upon the initialization of the machine learning models.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "eUAWebtzgrzm",
    "outputId": "421f1036-9483-4ef9-ae03-67d7271ee0ac"
   },
   "outputs": [],
   "source": [
    "C_grid = np.logspace(-2,2,10)\n",
    "\n",
    "time_start = timer()\n",
    "## Your code here\n",
    "...\n",
    "time_end = timer()\n",
    "\n",
    "print (\"Wall time for training & cross-validation: {0} second\".format(time_end-time_start))\n",
    "\n",
    "ax = plot_cv_curve(C_grid,train_scores,val_scores)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OZh2s3Y1n3is"
   },
   "source": [
    "Think about it (no need to write answers): does the curves above, especailly the training accuray vs. regularization parameter C, follow your expectation? Reminder: smaller C implies stronger regularization strength.\n",
    "***\n",
    "### 3.b Feature Scaling (3 points)\n",
    "You might have faced some numerical issues at first when training models for the last question. This is a common problem for gradient-based optimizations due to scale difference accross the features. The problem can be solved by [standardizing](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) the features, so all features have similar scales. The regularization also works better for standardized features (think about the reason.)\n",
    "\n",
    "**3.b)** Now, **standardize the features before training the model**, and repeat the hyperparameter tuning procedure in the last question to generate the cross-validation curve.\n",
    "\n",
    "**Submission format:**\n",
    "1. Store the training scores in an array with shape (10,5) called `train_scores`.\n",
    "2. Store the validation scores in an array with shaped (10,5) called `val_scores`.\n",
    "\n",
    "Detailed instructions remain the same as the last question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "yVBPBBaZdZGh",
    "outputId": "0ded1c1e-2962-4c2b-8207-0a46115d70d2"
   },
   "outputs": [],
   "source": [
    "# Logit with Standardization\n",
    "C_grid = np.logspace(-2,2,10)\n",
    "\n",
    "time_start = timer()\n",
    "## Your code here\n",
    "...\n",
    "time_end = timer()\n",
    "\n",
    "print (\"Wall time for training & cross-validation: {0} second\".format(time_end-time_start))\n",
    "\n",
    "ax = plot_cv_curve(C_grid,train_scores,val_scores)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d3-XkBBr7Hhb"
   },
   "source": [
    "Do you notice the difference in the performance and running time?\n",
    "***\n",
    "### 3.c Build a Pipeline Classifier (2 points)\n",
    "\n",
    "It is convenient to integrate the preprocessing steps with the classifier to form one [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), so you just need to pass the raw data through the Pipeline for training/prediction. \n",
    "\n",
    "**3.c)** Build a Pipeline classifier containing the following **two steps**:\n",
    "1. The first stage is a **StandardScaler()** that scales the input for the next stage.\n",
    "2. The second stage is a **LogisticRegression()** Classifier with C=0.3.\n",
    "\n",
    "Assign the Pipeline instance to a variable named `clf_logit`, and then train the Pipeline with all the training data (`X_train`,`y_train`.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "manual: false\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3hC5ehCEvCR",
    "outputId": "0c53795b-ff3c-45f2-f6ed-3581f3a9ebb8"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "...\n",
    "print (\"Train Accuracy is\", metrics.accuracy_score(y_train,clf_logit.predict(X_train)))\n",
    "print (\"Test Accuracy is\", metrics.accuracy_score(y_test,clf_logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKZnwxxCoaHc"
   },
   "source": [
    "## 4. K-Nearest Neighbors Vote Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udw9BTGuJ46n"
   },
   "source": [
    "Our next candidate model is the [K-Nearest Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#) (k-NN) classifier. We start by training a [k-NN classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) with default hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vFcMNRqHuiP",
    "outputId": "1f204749-56cb-4159-f5de-118b5d059763"
   },
   "outputs": [],
   "source": [
    "## Demo: training a default KNN model and cross-validate\n",
    "knn = KNeighborsClassifier()\n",
    "cv_scores = cross_val_score(knn,X_train,y_train,cv=kf)\n",
    "print (\"Cross-Validation Accuracies:\", cv_scores)\n",
    "print (\"Overall CV score is:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "q5kEqWJmKm8R"
   },
   "source": [
    "***\n",
    "### 4.a Cross-Validation: Number of Neighbors (3 points)\n",
    "\n",
    "The main hyperparameter for k-NN is `'n_neighbors'`, the number of nearest neighbors that is considered during classification. \n",
    "\n",
    "**4.a)** Twenty potential choices for `'n_neighbors'` are given in the `N_grid` array below. Train k-NN models for each n_neighbors in `N_grid`, and record the training and validation scores from the 5-fold cross-validation with folds defined by `kf`.\n",
    "\n",
    "**Submission format:**\n",
    "1. Store the training scores in an array with shape (20,5) called `train_scores`.\n",
    "2. Store the validation scores in an array with shaped (20,5) called `val_scores`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "GOABaLtOmkGH",
    "outputId": "61b813fc-89a7-4ec9-a19c-8fc79d53cfea"
   },
   "outputs": [],
   "source": [
    "N_grid = range(1,21)\n",
    "...\n",
    "\n",
    "ax = plot_cv_curve(N_grid,train_scores,val_scores)\n",
    "ax.set_xlabel('n_neighbors')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3NiONBs0LkFC"
   },
   "source": [
    "Think about it: how does the bias and variance of the model vary with `n_neighbor`?\n",
    "\n",
    "***\n",
    "### 4.b Challenge: Feature Engineering and Hyperparameter Tuning (6 points)\n",
    "\n",
    "**4.b)** Now you are ready to optimize the k-NN classifier on your own. Tune any k-NN hyperparameters to improve the cross-validation score. You may also engineer the features before applying k-NN classifications, but remember to concatenate all these steps into a single Pipeline.\n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_knn`.\n",
    "2. If `clf_knn` is a pipeline, the final stage must be a KNeighborsClassifier with the stage name being 'knn'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_knn`, `clf_knn` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>96% overall cross-validation (folds defined by `kf`) accuracy using `clf_knn`**. You will receive **50% credit for cross-validation accuracy of 95~96%**. \n",
    "\n",
    "The test \"q4b1\" checks if you achive >95% CV accuracy.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cm451N-mF7Wh",
    "outputId": "435856fb-73de-4a8c-940f-36a2820e4663"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage KNeighborsClassifier() named 'knn'\n",
    "## You can overwrite clf_knn with your own classifier\n",
    "clf_knn = Pipeline([('knn', KNeighborsClassifier())])\n",
    "\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final KNN Hyperparameters:\")\n",
    "print (clf_knn.named_steps['knn'] if clf_knn.__class__==Pipeline else clf_knn)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_knn,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yG5BDNBX4uw8"
   },
   "source": [
    "The test \"q4b2\" checks if you achive >96% CV accuracy.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cv5aLjegodRq"
   },
   "source": [
    "## 5. Support Vector Machine Classification\n",
    "\n",
    "[Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html#svm) (SVM) is a powerful algorithm suitable for a wide range of machine learning problems. We will stick to the [classification tasks](https://scikit-learn.org/stable/modules/svm.html#classification) for the rest of the homework, but SVM can actually be applied to regressions as well. We will start with the basic linear SVM, and then explore the empowering technique for non-linear modeling - the kernel trick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fU4o-14DNk7s"
   },
   "source": [
    "### 5.a Linear SVM (3 points)\n",
    "\n",
    "The [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) tries to learn a hyperplane that best separates different classes. Linear SVM defines margins for classification $w^T x + b = \\pm 1$ ($+1$ and $-1$ correspond to margins for different classes. See [mathematical detail](https://scikit-learn.org/stable/modules/svm.html#mathematical-formulation).)\n",
    "- Typically a [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss) is used to account for marginal and misclassified samples. The farther the misclassified sample is from the margin (i.e. the \"deeper\" the sample is misclassified into the wrong class), the larger the hinge loss. Minimizing this loss reduces misclassifications.\n",
    "- At the same time, we want the margin between classes to be large, which can be characterized by another loss $||w||^2$.\n",
    "\n",
    "SVM combines the two losses with a factor \"C\" before the hinge loss to control their relative effectiveness. The larger the C, the harder the SVM tries to classify samples correctly, but this can result in overfitting. Therefore, C is a regularization parameter that helps you control the softness of the decision, similar to what you have tuned for the logistic regression.\n",
    "\n",
    "**5.a)** To observe the effect of C, we have provided 9 potential choices in the array `C_grid` below. Train LinearSVC models for each C in `C_grid`, and record the training and validation scores from the 5-fold cross-validation with folds defined by `kf`.\n",
    "\n",
    "**Submission format:**\n",
    "1. **Standardize** the features before applying to SVM training and cross-validation.\n",
    "2. Use the **Standard hinge loss** for the classification. *(hint: this may not be the default setting of LinearSVC)*\n",
    "3. Again, manage to make all trainings converge.\n",
    "4. Store the training scores in an array with shape (9,5) called `train_scores`.\n",
    "5. Store the validation scores in an array with shaped (9,5) called `val_scores`.\n",
    "\n",
    "Remaining detailed instructions are the same as that for the first validation curve question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "YfV2MLeBUKuP",
    "outputId": "4c8f5e51-9b62-4a7e-c242-5f9f2ddac3eb"
   },
   "outputs": [],
   "source": [
    "C_grid = np.logspace(-2,2,9)\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "ax = plot_cv_curve(C_grid,train_scores,val_scores)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UOVzaIXKykM"
   },
   "source": [
    "Do the curves have the behaviors you expected?\n",
    "***\n",
    "LinearSVC already works very well, which means the classes are almost linearly separable. However, we are still curious to see if we can achieve an even-better performance with non-linear decision boundaries. Practically, non-linear functions (e.g. polynomials) of features are utilized through the [kernel functions](https://scikit-learn.org/stable/modules/svm.html#kernel-functions). It's ok not to understand all the math for this homework, but it is important to keep one thing in mind: more flexibility to the model means more engineering (e.g. hyperparameter tuning), or the model can be easily messed up and defeat by linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NPXrfu2UNtb5"
   },
   "source": [
    "### 5.b Challenge: Gaussian (aka Radial Basis Function) Kernel SVM (6 points)\n",
    "\n",
    "**5.b)** Optimize an [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) with 'rbf' kernel classifier. Tune any SVC hyperparameters to improve the cross-validation score. You may also engineer the features before applying SVM classifications, but remember to concatenate all these steps into a single Pipeline.\n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_svm_rbf`.\n",
    "2. If `clf_svm_rbf` is a pipeline, the final stage must be an SVC with the stage name being 'svc'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_svm_rbf`, `clf_svm_rbf` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>97.5% overall cross-validation (folds defined by `kf`) accuracy using `clf_svm_rbf`**. You will receive **50% credit for cross-validation accuracy of 96%~97.5%**.\n",
    "\n",
    "**Hint: Aside from `C`, rbf-kernel SVM is controlled by another hyperparameter `gamma`.**\n",
    "\n",
    "The test \"q5b1\" checks if you achive >96% CV accuracy.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG2Bwp8y64VH",
    "outputId": "bd5fa0ca-bff1-4567-82ff-7a58c928fe13"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage SVC() named 'svc' with rbf kernel\n",
    "## You can overwrite clf_svm_rbf with your own classifier\n",
    "clf_svm_rbf = Pipeline([('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final SVM Hyperparameters:\")\n",
    "print (clf_svm_rbf.named_steps['svc'] if clf_svm_rbf.__class__==Pipeline else clf_svm_rbf)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_svm_rbf,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_svm_rbf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "--zOBrgbUz9t"
   },
   "source": [
    "The test \"q5b2\" checks if you achive >97.5% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ARotOKQ2OxOE"
   },
   "source": [
    "### 5.c Challenge: Polynomial Kernel SVM (6 points)\n",
    "**5.c)** Optimize an SVC with 'poly' kernel classifier. Tune any SVC hyperparameters to improve the cross-validation score. You may also engineer the features before applying SVM classifications, but remember to concatenate all these steps into a single Pipeline.\n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_svm_poly`.\n",
    "2. If `clf_svm_poly` is a pipeline, the final stage must be an SVC with the stage name being 'svc'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_svm_poly`, `clf_svm_poly` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>97.5% overall cross-validation (folds defined by `kf`) accuracy using `clf_svm_poly`**. You will receive **50% credit for cross-validation accuracy of 96%~97.5%**.\n",
    "\n",
    "**Hint: Consult the [document](https://scikit-learn.org/stable/modules/svm.html#svm-kernels) for the relevant hyperparameters of poly kernel.**\n",
    "\n",
    "The test \"q5c1\" checks if you achive >96% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWSOmIVRAPsv",
    "outputId": "dcce7703-7df1-4b17-c21b-8de1ce22b662"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage SVC() named 'svc' with poly kernel\n",
    "## You can overwrite clf_svm_poly with your own classifier\n",
    "clf_svm_poly = Pipeline([('svc', SVC(kernel='poly'))])\n",
    "\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final SVM Hyperparameters:\")\n",
    "print (clf_svm_poly.named_steps['svc'] if clf_svm_poly.__class__==Pipeline else clf_svm_poly)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_svm_poly,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_svm_poly.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9wlynuJKU3HF"
   },
   "source": [
    "The test \"q5c2\" checks if you achive >97.5% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJTSfyupD2xp"
   },
   "source": [
    "## 6. Decision Tree\n",
    "\n",
    "\n",
    "[Decision Tree](https://scikit-learn.org/stable/modules/tree.html) can be used for both linear and non-linear data, and can be used for both classification and regression problems. In lectures, you were given a basic introduction to decision trees and how such trees are trained. Here, we will dive deep and learn how the hyperparameters can impact the decision tree models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa8Xi3OMnuC6"
   },
   "source": [
    "We start by training a decision tree classifier with default hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvTqZWSbnuDE",
    "outputId": "f2e29836-d635-4f0f-a025-9849fdefb99e"
   },
   "outputs": [],
   "source": [
    "## Demo: training a default decision tree model and cross-validate\n",
    "dt_model = DecisionTreeClassifier(random_state=0)\n",
    "dt_cv_scores = cross_val_score(dt_model,X_train,y_train,cv=kf)\n",
    "print (\"Cross-Validation Accuracies:\", dt_cv_scores)\n",
    "print (\"Overall CV score is:\", np.mean(dt_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FAUiaCMLpdAk"
   },
   "source": [
    "***\n",
    "### 6.a Cross-Validation: Maximum Depth of Tree (3 points)\n",
    "A basic decision tree algorithm keeps subdividing tree nodes until every leaf is pure. Sometimes, due to the noise existing in data, it may cause overfitting. To limit tree size and depth for speed and avoiding overfitting, we need pre-pruning, that is to say, stopping the tree-building process early.\n",
    "One common stopping condition is setting the maximum depth, that means when a decision tree arrives at a certain depth, it will stop dividing.\n",
    "\n",
    "**6.a)** Twenty potential choices for `'max_depth'` are given in the `max_dep` array below. Train decision tree models for each max_depth in `max_dep`, and record the training and validation scores from the 5-fold cross-validation with folds defined by `kf`.\n",
    "\n",
    "**Submission format:**\n",
    "1. Store the training scores in an array with shape (20,5) called `train_scores`.\n",
    "2. Store the validation scores in an array with shaped (20,5) called `val_scores`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "FG8xdT-tHDvq",
    "outputId": "1120c779-c720-4f47-9fd0-1ad8f94a31b3"
   },
   "outputs": [],
   "source": [
    "max_dep = range(1,21)\n",
    "...\n",
    "ax = plot_cv_curve(max_dep,train_scores,val_scores)\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XgK2l_sDNPV2"
   },
   "source": [
    "***\n",
    "### 6.b Challenge: Feature Engineering and Hyperparameter Tuning (6 points)\n",
    "\n",
    "Except for 'max_depth', there are also other [hyperparameters](https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680) are critical, such as 'max_leaf_nodes', 'min_samples_split', 'min_samples_leaf', etc. \n",
    "\n",
    "For example, the minimum sample split is the minimum sample number in\n",
    "an internal node. If the number of samples in a node is\n",
    "smaller than the minimum sample split, it will stop\n",
    "splitting. The minimum sample leaf means the minimum\n",
    "number of samples required to be at a leaf node.\n",
    "\n",
    "**6.b)** Now you are ready to optimize the decision tree classifier on your own. Tune any decision tree hyperparameters to improve the cross-validation score. You may also engineer the features before applying decision tree classifications, but remember to concatenate all these steps into a single Pipeline.\n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_dt`.\n",
    "2. If `clf_dt` is a pipeline, the final stage must be a DecisionTreeClassifier with the stage name being 'dt'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_dt`, `clf_dt` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>92.5% overall cross-validation (folds defined by `kf`) accuracy using `clf_dt`**. You will receive **50% credit for cross-validation accuracy of 92~92.5%**. \n",
    "\n",
    "The test \"q6b1\" checks if you achive >92.5% CV accuracy.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAdJHWmy4jzX",
    "outputId": "7e9e39e6-fc8f-43ef-bc77-ea559eca46dd"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage DecisionTreeClassifier() named 'dt'\n",
    "## You can overwrite clf_dt with your own classifier\n",
    "clf_dt = Pipeline([('dt',DecisionTreeClassifier())])\n",
    "\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final Decision Tree Hyperparameters:\")\n",
    "print (clf_dt.named_steps['dt'] if clf_dt.__class__==Pipeline else clf_dt)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_dt,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6802bwNvTKFV"
   },
   "source": [
    "The test \"q6b2\" checks if you achive >92% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzs57w3QEBd_"
   },
   "source": [
    "## 7. Ensemble Method 1: Random Forest\n",
    "\n",
    "Now we get better ideas about decision trees. The basic idea of [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) is to build many decision trees and have them vote. Therefore, random forest can help to improve the classification accuracy and prevent overfitting. But we only have one training set, how can we build many trees using only one dataset? \n",
    "\n",
    "\n",
    "Random forest will use several decision tree classifiers on various sub-samples of the dataset and use the average of them. The sub-sample size is controlled with the 'max_samples' parameter if bootstrap=True (default), and otherwise the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEEJplWythqj",
    "outputId": "97b4687e-caaa-46ec-ceef-5327c6c07994"
   },
   "outputs": [],
   "source": [
    "## Demo: training a default random forest model and cross-validate\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "rf_cv_scores = cross_val_score(rf_model,X_train,y_train,cv=kf)\n",
    "print (\"Cross-Validation Accuracies:\", rf_cv_scores)\n",
    "print (\"Overall CV score is:\", np.mean(rf_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WT1oeTZuvkox"
   },
   "source": [
    "***\n",
    "### 7.a Challenge: Feature Engineering and Hyperparameter Tuning (6 points)\n",
    "\n",
    "Similar to decision tree, you can also tune the hyperparameters of your random forest classifier. \n",
    "\n",
    "**7.a)** Please try to tune any random forest hyperparameters to improve the cross-validation score. You may also engineer the features before applying random forest classifications, but remember to concatenate all these steps into a single Pipeline.\n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_rf`.\n",
    "2. If `clf_rf` is a pipeline, the final stage must be a RandomForestClassifier with the stage name being 'rf'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_rf`, `clf_rf` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>95.5% overall cross-validation (folds defined by `kf`) accuracy using `clf_rf`**. You will receive **50% credit for cross-validation accuracy of 95~95.5%**. \n",
    "\n",
    "The test \"q7a1\" checks if you achive >95.5% CV accuracy.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhAWZnI-vkoy",
    "outputId": "cd4fbdbc-2898-4aa8-bef6-16b9f216b3e0"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage RandomForestClassifier() named 'rf'\n",
    "## You can overwrite clf_rf with your own classifier\n",
    "clf_rf = Pipeline([('rf',RandomForestClassifier())])\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final Random Forest Hyperparameters:\")\n",
    "print (clf_rf.named_steps['rf'] if clf_rf.__class__==Pipeline else clf_rf)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_rf,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-AZ7bXK2_lCo"
   },
   "source": [
    "The test \"q7a2\" checks if you achive >95% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR6-u6BQoiVt"
   },
   "source": [
    "## 8. Ensemble Method 2: AdaBoost\n",
    "\n",
    "[AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) (Adaptive Boosting) is a ensemble boosting classifier. It combines multiple classifiers to increase the accuracy of classifiers. AdaBoost classifier builds a strong classifier by combining multiple poorly performing classifiers so that you will get high accuracy strong classifier. \n",
    "The hyperparameters of AdaBoost classifier includes base_estimator, n_estimators, learning_rate, etc.\n",
    "\n",
    "- base_estimator: It is a weak learner used to train the model. It uses DecisionTreeClassifier with max_depth=1 as default weak learner for training purpose. You can also specify different machine learning algorithms.\n",
    "- n_estimators: Number of weak learners to train iteratively.\n",
    "- learning_rate: It contributes to the weights of weak learners. It uses 1 as a default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZiTwpKruJImP",
    "outputId": "c4093758-08a7-40c1-b25d-c4cc88d5ac84"
   },
   "outputs": [],
   "source": [
    "## Demo: training a default AdaBoost model and cross-validate\n",
    "adaboost_model = AdaBoostClassifier(random_state=0)\n",
    "rf_cv_scores = cross_val_score(adaboost_model,X_train,y_train,cv=kf)\n",
    "print (\"Cross-Validation Accuracies:\", rf_cv_scores)\n",
    "print (\"Overall CV score is:\", np.mean(rf_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4D25YKOFMSm1"
   },
   "source": [
    "### 8.a Challenge: Feature Engineering and Hyperparameter Tuning (6 points)\n",
    "\n",
    "**8.a)** You can use the same method to tune the hyperparameters of your AdaBoost classifier. \n",
    "\n",
    "**Submission Format (read carefully):**\n",
    "1. Store the final classifier in a vairable named `clf_ab`.\n",
    "2. If `clf_ab` is a pipeline, the final stage must be a AdaBoostClassifier with the stage name being 'ab'. This is to ensure the grader can parse your submission.\n",
    "3. Whether or not there are preprocessing stages in `clf_ab`, `clf_ab` must take the same input format as `X_train` and `X_test` for classifying the tumor.\n",
    "\n",
    "You will receive full credit for this problem if you achieve **>96.5% overall cross-validation (folds defined by `kf`) accuracy using `clf_ab`**. You will receive **50% credit for cross-validation accuracy of 96~96.5%**. \n",
    "\n",
    "The test \"q8a1\" checks if you achive >96.5% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8a1\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csJk7P3oJWN4",
    "outputId": "f250fa47-40e6-410d-f5be-1347064aae69"
   },
   "outputs": [],
   "source": [
    "## Example: declare a pipeline with only one stage AdaBoostClassifier() named 'ab'\n",
    "## You can overwrite clf_ab with your own classifier\n",
    "clf_ab = Pipeline([('ab',AdaBoostClassifier())])\n",
    "## Your code here\n",
    "...\n",
    "\n",
    "print (\"Final AdaBoost Hyperparameters:\")\n",
    "print (clf_ab.named_steps['ab'] if clf_ab.__class__==Pipeline else clf_ab)\n",
    "print (\"Overall CV score is:\", np.mean(cross_val_score(clf_ab,X_train,y_train,cv=kf)))\n",
    "print (\"Test Accuracy is:\", metrics.accuracy_score(y_test,clf_ab.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8a1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yv9qFAldNL-j"
   },
   "source": [
    "The test \"q8a2\" checks if you achive >96% CV accuracy.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8a2\n",
    "manual: false\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy Cell, DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8a2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqyd07RANhN_"
   },
   "source": [
    "# Wrap-up: Model Comparison\n",
    "Now you have successfully trained several models and tuned the hyperparameters of them. Which model performs the best with the breast cancer dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "ieFNoDJ7NdMU",
    "outputId": "f2e03e59-4957-4bdf-df33-9396d4af36ab"
   },
   "outputs": [],
   "source": [
    "Model_dict = {\n",
    "    'Logistic regression':clf_logit, 'k-NN': clf_knn,\n",
    "    'SVM (RBF Kernel)': clf_svm_rbf, 'SVM (Poly Kernel)': clf_svm_poly,\n",
    "    'Decision Tree': clf_dt, 'Ramdom Forest': clf_rf, 'AdaBoost': clf_ab\n",
    "}\n",
    "## Run the cell to view your accuracy of all the models\n",
    "models = []\n",
    "errors = []\n",
    "for modelname, clf in Model_dict.items():\n",
    "  models.append(modelname)\n",
    "  errors.append((1-metrics.accuracy_score(y_test,clf.predict(X_test)))*100)\n",
    "df_test_erorr = pd.DataFrame({\"Model\":models,\"Test Error Rate (%)\":errors})\n",
    "df_test_erorr.sort_values(by=\"Test Error Rate (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlWFHW7UAjyQ"
   },
   "source": [
    "Now pick the best model you found in the previous cell to view the importance of each feature in this dataset. Here, we will use a function called \"[permutation_importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\". The permutation feature importance function helps to calculate the importance of estimators for the dataset. The n_repeats parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances. \n",
    "\n",
    "Now you can put the name of the best model you found from previous question in the variable called \"best_model\", and run the following 2 cells: one to plot the importance of training dataset and one for testing dataset. What do you find from the two plots? Do they agree with each other?\n",
    "\n",
    "**This section will not be graded.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "bLJYEfLogJdo",
    "outputId": "8d03ba49-802d-44ce-ba5f-97c0945b247a"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "best_model = ...\n",
    "\n",
    "result = permutation_importance(best_model,X_train,y_train,n_repeats=10)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_train.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "98ErOQmbkpaV",
    "outputId": "e6bea6ba-09cb-4902-96f2-f0da25c5b92f"
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(best_model,X_test,y_test,n_repeats=10)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_test.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to create a pdf for your reference."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_CoreConcepts.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
